{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX4vTfs8ep3h",
        "outputId": "6477fba3-0f49-4026-8144-e124622c9c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctfZlOXZ0XAC",
        "outputId": "21c0b94f-f168-42b9-bf8d-cc8a5b734fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb0OZeJCgJYD",
        "outputId": "27b4c1c7-8110-489f-a0a9-fccd9b1bdacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path where you want to create the folder\n",
        "folder_path = '/content/drive/My Drive/colabdiff'\n",
        "\n",
        "# Create the folder\n",
        "os.makedirs(folder_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "rq-Gc6U1gXJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/My Drive/colabdiff/'"
      ],
      "metadata": {
        "id": "0VzVB7IThEui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ziqihuangg/Collaborative-Diffusion.git\n"
      ],
      "metadata": {
        "id": "iWMGur5hhIyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/My Drive/colabdiff/Collaborative-Diffusion'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mRZPv8A8a0K",
        "outputId": "46181bda-a351-48ff-e1f1-6c3ee25147c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/colabdiff/Collaborative-Diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4Or9l2ai15X",
        "outputId": "24adfc36-8ac5-4f56-fc87-290445b06e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/   environment.yaml  \u001b[01;34mldm\u001b[0m/     mask2image.py  README.md   text2image.py\n",
            "\u001b[01;34mconfigs\u001b[0m/  \u001b[01;34mfreeu\u001b[0m/            LICENSE  \u001b[01;34moutputs\u001b[0m/       setup.py\n",
            "\u001b[01;34mediting\u001b[0m/  generate.py       main.py  \u001b[01;34mpretrained\u001b[0m/    \u001b[01;34mtest_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Download and put the models under Collaborative-Diffusion/pretrained from https://drive.google.com/drive/folders/13MdDea8eI8P4ygeIyfy8krlTb8Ty0mAP\n",
        "\n",
        "1. 512_codiff_mask_text.ckpt\n",
        "2. 512_mask.ckpt\n",
        "3. 512_text.ckpt\n",
        "4. 512_vae.ckpt\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n1G1YIDKhT72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf\n",
        "!pip install einops\n",
        "!pip install pytorch-lightning==1.6.5\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install taming-transformers-rom1504\n",
        "!pip install kornia"
      ],
      "metadata": {
        "id": "tU07KAbZuwAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for more masked images get it from herehttps://drive.google.com/drive/folders/1rLcdN-VctJpW4k9AfSXWk0kqxh329xc4"
      ],
      "metadata": {
        "id": "3KOIx0DxiVGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --mask_path test_data/512_masks/1234.png --input_text \"She is in her thirties.\""
      ],
      "metadata": {
        "id": "VfMuW0BcjOQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fb13ff-38c0-47f6-e591-2298c5b43cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up model\n",
            "2024-04-24 15:20:40.218152: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-24 15:20:40.218201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-24 15:20:40.333859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-24 15:20:41.493391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "kwargs:{'linear_start': 0.0015, 'linear_end': 0.0195, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'image_size': 64, 'channels': 3, 'monitor': 'val/loss_simple'}\n",
            "LatentDiffusionCompose: Running in eps-prediction mode\n",
            "\n",
            "LatentDiffusionCompose: instantiate seg_mask branch from pretrained/512_mask.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "instantiate_from_config --- module: ldm.modules.encoders.modules, cls: PassSegMaskEncoder\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_mask.ckpt\n",
            "Restored from pretrained/512_mask.ckpt with 0 missing and 0 unexpected keys\n",
            "\n",
            "LatentDiffusionCompose: instantiate text branch from pretrained/512_text.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 248kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.40MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 5.61MB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 2.60MB/s]\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_text.ckpt\n",
            "Restored from pretrained/512_text.ckpt with 0 missing and 0 unexpected keys\n",
            "start instantiate_from_config compose_unet_config\n",
            "self.enable_freeu = False\n",
            "self.enable_freeu = False\n",
            "finish instantiate_from_config compose_unet_config\n",
            "ComposeUNet has 833.52 M params.\n",
            "LatentDiffusionCompose: self.use_ema=False\n",
            "finished initialiation of LatentDiffusionCompose\n",
            "Restored from pretrained/512_codiff_mask_text.ckpt with 0 missing and 0 unexpected keys\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/colabdiff/Collaborative-Diffusion/generate.py\", line 269, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/My Drive/colabdiff/Collaborative-Diffusion/generate.py\", line 126, in main\n",
            "    flattened_img_tensor_one_hot = F.one_hot(\n",
            "RuntimeError: Class values must be smaller than num_classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/29980.png \\\n",
        "--input_text \"This woman is in her forties.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpB1PMM5__6W",
        "outputId": "f414e96f-0d11-4a8a-9336-c6ed7ac6f5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up model\n",
            "2024-04-24 13:59:57.630937: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-24 13:59:57.630990: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-24 13:59:57.712699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-24 13:59:59.939355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "kwargs:{'linear_start': 0.0015, 'linear_end': 0.0195, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'image_size': 64, 'channels': 3, 'monitor': 'val/loss_simple'}\n",
            "LatentDiffusionCompose: Running in eps-prediction mode\n",
            "\n",
            "LatentDiffusionCompose: instantiate seg_mask branch from pretrained/512_mask.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "instantiate_from_config --- module: ldm.modules.encoders.modules, cls: PassSegMaskEncoder\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_mask.ckpt\n",
            "Restored from pretrained/512_mask.ckpt with 0 missing and 0 unexpected keys\n",
            "\n",
            "LatentDiffusionCompose: instantiate text branch from pretrained/512_text.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_text.ckpt\n",
            "Restored from pretrained/512_text.ckpt with 0 missing and 0 unexpected keys\n",
            "start instantiate_from_config compose_unet_config\n",
            "self.enable_freeu = False\n",
            "self.enable_freeu = False\n",
            "finish instantiate_from_config compose_unet_config\n",
            "ComposeUNet has 833.52 M params.\n",
            "LatentDiffusionCompose: self.use_ema=False\n",
            "finished initialiation of LatentDiffusionCompose\n",
            "Restored from pretrained/512_codiff_mask_text.ckpt with 0 missing and 0 unexpected keys\n",
            "================================================================================\n",
            "mask_path: test_data/512_masks/29980.png | text: This woman is in her forties.\n",
            "Data shape for DDIM sampling is (1, 3, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]/content/drive/My Drive/colabdiff/Collaborative-Diffusion/ldm/models/diffusion/compose_modules.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  schedule_scale =  (torch.cos( torch.tensor((1-(t/1000)) * (pi)))+1)/2\n",
            "DDIM Sampler: 100% 50/50 [00:16<00:00,  3.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/2998011.png \\\n",
        "--input_text \"This woman is in her forties.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz5lVKJFKovo",
        "outputId": "425f6894-b079-41fd-91f9-088a796c94cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up model\n",
            "2024-04-26 17:01:21.179220: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-26 17:01:21.179272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-26 17:01:21.181603: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-26 17:01:22.432770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "kwargs:{'linear_start': 0.0015, 'linear_end': 0.0195, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'image_size': 64, 'channels': 3, 'monitor': 'val/loss_simple'}\n",
            "LatentDiffusionCompose: Running in eps-prediction mode\n",
            "\n",
            "LatentDiffusionCompose: instantiate seg_mask branch from pretrained/512_mask.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "instantiate_from_config --- module: ldm.modules.encoders.modules, cls: PassSegMaskEncoder\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_mask.ckpt\n",
            "Restored from pretrained/512_mask.ckpt with 0 missing and 0 unexpected keys\n",
            "\n",
            "LatentDiffusionCompose: instantiate text branch from pretrained/512_text.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 208kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 13.2MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 47.8MB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.34MB/s]\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_text.ckpt\n",
            "Restored from pretrained/512_text.ckpt with 0 missing and 0 unexpected keys\n",
            "start instantiate_from_config compose_unet_config\n",
            "self.enable_freeu = False\n",
            "self.enable_freeu = False\n",
            "finish instantiate_from_config compose_unet_config\n",
            "ComposeUNet has 833.52 M params.\n",
            "LatentDiffusionCompose: self.use_ema=False\n",
            "finished initialiation of LatentDiffusionCompose\n",
            "Restored from pretrained/512_codiff_mask_text.ckpt with 0 missing and 0 unexpected keys\n",
            "================================================================================\n",
            "mask_path: test_data/512_masks/2998011.png | text: This woman is in her forties.\n",
            "Data shape for DDIM sampling is (1, 3, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]/content/drive/MyDrive/colabdiff/Collaborative-Diffusion/ldm/models/diffusion/compose_modules.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  schedule_scale =  (torch.cos( torch.tensor((1-(t/1000)) * (pi)))+1)/2\n",
            "DDIM Sampler: 100% 50/50 [00:17<00:00,  2.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --mask_path test_data/512_masks/27007.png --input_text \"He is a teen. The face is covered wtih short pointed beard.\""
      ],
      "metadata": {
        "id": "a9Uqgf2FAq-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --mask_path test_data/512_masks/27007.png --input_text \"This man has beard of medium length. He is in his thirties.\" --save_z 1"
      ],
      "metadata": {
        "id": "taCDpdM6Aubj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --mask_path test_data/512_masks/27007.png --input_text \"He looks very old. He has more wrinkles on his face\""
      ],
      "metadata": {
        "id": "89zLGU44Auhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/29980.png \\\n",
        "--input_text \"She is in her twenties. She has thick eyebrows and her skin color is brown.\""
      ],
      "metadata": {
        "id": "CKshQvUDSNjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/733.png \\\n",
        "--input_text \"This female has no beard at all. This person is a teenager..\""
      ],
      "metadata": {
        "id": "-Mp9m3_Etq1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/1377.png \\\n",
        "--input_text \"He is in his thirties. The face is covered with thick beard.\""
      ],
      "metadata": {
        "id": "2dx731ikuB25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/18541.png \\\n",
        "--input_text \"This gentleman doesn't have any beard at all. This guy looks extremely young.\""
      ],
      "metadata": {
        "id": "yC3OpkEGvvp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/18781.png \\\n",
        "--input_text \"This female looks very young. This female has no beard.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByTXZwZIyuMO",
        "outputId": "0eae337e-f296-402c-8170-b64e80d42275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up model\n",
            "2024-02-23 16:41:10.976399: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-23 16:41:10.976451: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-23 16:41:10.984253: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-23 16:41:13.396725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "kwargs:{'linear_start': 0.0015, 'linear_end': 0.0195, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'image_size': 64, 'channels': 3, 'monitor': 'val/loss_simple'}\n",
            "LatentDiffusionCompose: Running in eps-prediction mode\n",
            "\n",
            "LatentDiffusionCompose: instantiate seg_mask branch from pretrained/512_mask.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "instantiate_from_config --- module: ldm.modules.encoders.modules, cls: PassSegMaskEncoder\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_mask.ckpt\n",
            "Restored from pretrained/512_mask.ckpt with 0 missing and 0 unexpected keys\n",
            "\n",
            "LatentDiffusionCompose: instantiate text branch from pretrained/512_text.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "DDPM Compose - instantiate_ldm - ckpt_path=pretrained/512_text.ckpt\n",
            "Restored from pretrained/512_text.ckpt with 0 missing and 0 unexpected keys\n",
            "start instantiate_from_config compose_unet_config\n",
            "self.enable_freeu = False\n",
            "self.enable_freeu = False\n",
            "finish instantiate_from_config compose_unet_config\n",
            "ComposeUNet has 833.52 M params.\n",
            "LatentDiffusionCompose: self.use_ema=False\n",
            "finished initialiation of LatentDiffusionCompose\n",
            "Restored from pretrained/512_codiff_mask_text.ckpt with 0 missing and 0 unexpected keys\n",
            "================================================================================\n",
            "mask_path: test_data/512_masks/18781.png | text: This female looks very young. This female has no beard.\n",
            "Data shape for DDIM sampling is (1, 3, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]/content/drive/MyDrive/colabdiff/Collaborative-Diffusion/ldm/models/diffusion/compose_modules.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  schedule_scale =  (torch.cos( torch.tensor((1-(t/1000)) * (pi)))+1)/2\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "--mask_path test_data/512_masks/18697.png \\\n",
        "--input_text \"This gentleman doesn't have hair at all. He is in his eighties\""
      ],
      "metadata": {
        "id": "iHoubzZe2zSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python mask2image.py \\\n",
        "--mask_path test_data/512_masks/2998011.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51mJyjl6OkDI",
        "outputId": "b634faa5-bc05-4b01-98ab-1630f8004fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up model\n",
            "2024-04-26 16:58:23.650568: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-26 16:58:23.650633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-26 16:58:23.652584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-26 16:58:25.583461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "instantiate_from_config --- module: ldm.modules.encoders.modules, cls: PassSegMaskEncoder\n",
            "Restored from pretrained/512_mask.ckpt with 0 missing and 0 unexpected keys\n",
            "Converted to L\n",
            "================================================================================\n",
            "mask_path: test_data/512_masks/2998011.png\n",
            "Data shape for DDIM sampling is (4, 3, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python mask2image.py \\\n",
        "--mask_path test_data/512_masks/29980.png"
      ],
      "metadata": {
        "id": "mFAD0rDv-e8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1732bb-fc9d-4e71-d5ab-09981269b6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up model\n",
            "2024-04-26 07:41:58.219499: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-26 07:41:58.219548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-26 07:41:58.221466: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-26 07:42:00.151566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "self.enable_freeu = False\n",
            "DiffusionWrapper has 403.62 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from pretrained/512_vae.ckpt\n",
            "instantiate_from_config --- module: ldm.modules.encoders.modules, cls: PassSegMaskEncoder\n",
            "Restored from pretrained/512_mask.ckpt with 0 missing and 0 unexpected keys\n",
            "Flattened Image Tensor: tensor([ 0,  0,  0,  ..., 13, 13, 13])\n",
            "Number of pixels in the image: 1024\n",
            "Number of unique color palettes: 13\n",
            "================================================================================\n",
            "mask_path: test_data/512_masks/29980.png\n",
            "Data shape for DDIM sampling is (4, 3, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [00:15<00:00,  3.24it/s]\n"
          ]
        }
      ]
    }
  ]
}